Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:126] Couldn't open CUDA library libcudnn.so.5. LD_LIBRARY_PATH: 
I tensorflow/stream_executor/cuda/cuda_dnn.cc:3517] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Reading Glove vectors... 
Creating embedding matrix for Keras... 
Iterating over question samples to extract metadata...
Data generator initialized
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2122b00
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:05.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2526620
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:06.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2158ec0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:07.0
Total memory: 11.17GiB
Free memory: 11.11GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N N N 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y N N 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2:   N N Y N 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3:   N N N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:00:06.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:00:07.0)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
q1_input (InputLayer)            (None, 272)           0                                            
____________________________________________________________________________________________________
q2_input (InputLayer)            (None, 272)           0                                            
____________________________________________________________________________________________________
embedding_1 (Embedding)          (None, 272, 200)      80000400    q1_input[0][0]                   
                                                                   q2_input[0][0]                   
____________________________________________________________________________________________________
gru_1 (GRU)                      (None, 128)           126336      embedding_1[0][0]                
                                                                   embedding_1[1][0]                
____________________________________________________________________________________________________
merge_1 (Merge)                  (None, 256)           0           gru_1[0][0]                      
                                                                   gru_1[1][0]                      
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1)             257         merge_1[0][0]                    
====================================================================================================
Total params: 80,126,993
Trainable params: 80,126,993
Non-trainable params: 0
____________________________________________________________________________________________________
None
Epoch 1/10
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 24052 get requests, put_count=7924 evicted_count=1000 eviction_rate=0.126199 and unsatisfied allocation rate=0.716281
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 9017 get requests, put_count=18027 evicted_count=9000 eviction_rate=0.499251 and unsatisfied allocation rate=0.000110902
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2013 get requests, put_count=4026 evicted_count=2000 eviction_rate=0.496771 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 12024 get requests, put_count=24037 evicted_count=12000 eviction_rate=0.49923 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4992 get requests, put_count=10008 evicted_count=5000 eviction_rate=0.4996 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 13572 get requests, put_count=28588 evicted_count=15000 eviction_rate=0.524696 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 8028 get requests, put_count=16047 evicted_count=8000 eviction_rate=0.498536 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 999 get requests, put_count=2022 evicted_count=1000 eviction_rate=0.49456 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 10986 get requests, put_count=22009 evicted_count=11000 eviction_rate=0.499796 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4028 get requests, put_count=8056 evicted_count=4000 eviction_rate=0.496524 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 13340 get requests, put_count=27368 evicted_count=14000 eviction_rate=0.511546 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 7074 get requests, put_count=14107 evicted_count=7000 eviction_rate=0.496208 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1269 get requests, put_count=2284 evicted_count=1000 eviction_rate=0.437828 and unsatisfied allocation rate=0.0173365
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 409 to 449
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 10040 get requests, put_count=20080 evicted_count=10000 eviction_rate=0.498008 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3057 get requests, put_count=6106 evicted_count=3000 eviction_rate=0.49132 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 12629 get requests, put_count=25678 evicted_count=13000 eviction_rate=0.50627 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 7071 get requests, put_count=14130 evicted_count=7000 eviction_rate=0.4954 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1190 get requests, put_count=2250 evicted_count=1000 eviction_rate=0.444444 and unsatisfied allocation rate=0.00420168
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 720 to 792
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 10074 get requests, put_count=20146 evicted_count=10000 eviction_rate=0.496376 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4099 get requests, put_count=8186 evicted_count=4000 eviction_rate=0.488639 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 13152 get requests, put_count=27239 evicted_count=14000 eviction_rate=0.513969 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 8102 get requests, put_count=16197 evicted_count=8000 eviction_rate=0.493919 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2107 get requests, put_count=4212 evicted_count=2000 eviction_rate=0.474834 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 12093 get requests, put_count=24198 evicted_count=12000 eviction_rate=0.495909 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 6133 get requests, put_count=12248 evicted_count=6000 eviction_rate=0.489876 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 39066 get requests, put_count=39235 evicted_count=16000 eviction_rate=0.407799 and unsatisfied allocation rate=0.408181
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 1273 to 1400
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 10132 get requests, put_count=20259 evicted_count=10000 eviction_rate=0.493608 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4130 get requests, put_count=8284 evicted_count=4000 eviction_rate=0.482859 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 12825 get requests, put_count=26978 evicted_count=14000 eviction_rate=0.518941 and unsatisfied allocation rate=7.79727e-05
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 9170 get requests, put_count=18339 evicted_count=9000 eviction_rate=0.490757 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4185 get requests, put_count=8370 evicted_count=4000 eviction_rate=0.477897 and unsatisfied allocation rate=0.000238949
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 13271 get requests, put_count=27456 evicted_count=14000 eviction_rate=0.509907 and unsatisfied allocation rate=7.53523e-05
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 8212 get requests, put_count=16416 evicted_count=8000 eviction_rate=0.487329 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3232 get requests, put_count=6457 evicted_count=3000 eviction_rate=0.464612 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 12101 get requests, put_count=25326 evicted_count=13000 eviction_rate=0.513306 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 9237 get requests, put_count=18484 evicted_count=9000 eviction_rate=0.486908 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4276 get requests, put_count=8548 evicted_count=4000 eviction_rate=0.467946 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 38924 get requests, put_count=38978 evicted_count=14000 eviction_rate=0.359177 and unsatisfied allocation rate=0.365276
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 2997 to 3296
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 10314 get requests, put_count=20613 evicted_count=10000 eviction_rate=0.485131 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 6309 get requests, put_count=12638 evicted_count=6000 eviction_rate=0.474759 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3382 get requests, put_count=6744 evicted_count=3000 eviction_rate=0.44484 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 11843 get requests, put_count=25205 evicted_count=13000 eviction_rate=0.515771 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 9393 get requests, put_count=18791 evicted_count=9000 eviction_rate=0.478953 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 6420 get requests, put_count=12858 evicted_count=6000 eviction_rate=0.466636 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4474 get requests, put_count=8956 evicted_count=4000 eviction_rate=0.446628 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2540 get requests, put_count=5070 evicted_count=2000 eviction_rate=0.394477 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1581 get requests, put_count=3164 evicted_count=1000 eviction_rate=0.316056 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 39656 get requests, put_count=40429 evicted_count=11000 eviction_rate=0.272082 and unsatisfied allocation rate=0.272594
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 6418 to 7059
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 39349 get requests, put_count=39820 evicted_count=10000 eviction_rate=0.25113 and unsatisfied allocation rate=0.258456
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 7059 to 7764
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 40146 get requests, put_count=41386 evicted_count=10000 eviction_rate=0.241628 and unsatisfied allocation rate=0.235764
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 7764 to 8540
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2839 get requests, put_count=5693 evicted_count=2000 eviction_rate=0.351309 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4957 get requests, put_count=9896 evicted_count=4000 eviction_rate=0.404204 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2122 get requests, put_count=4258 evicted_count=1000 eviction_rate=0.234852 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 39357 get requests, put_count=41274 evicted_count=1000 eviction_rate=0.0242283 and unsatisfied allocation rate=0.015118
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 16639 to 18302
/home/tianwang/.local/lib/python3.5/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.
  warnings.warn('Epoch comprised more than '
6419s - loss: 0.5216 - acc: 0.7418 - val_loss: 0.4833 - val_acc: 0.7706
Epoch 2/10
6402s - loss: 0.4710 - acc: 0.7776 - val_loss: 0.4714 - val_acc: 0.7791
Epoch 3/10
6374s - loss: 0.4289 - acc: 0.8031 - val_loss: 0.4694 - val_acc: 0.7802
Epoch 4/10
6421s - loss: 0.3845 - acc: 0.8292 - val_loss: 0.4817 - val_acc: 0.7788
Epoch 5/10
6394s - loss: 0.3391 - acc: 0.8537 - val_loss: 0.5082 - val_acc: 0.7721
Epoch 6/10
6419s - loss: 0.2946 - acc: 0.8762 - val_loss: 0.5494 - val_acc: 0.7657
Epoch 7/10
6379s - loss: 0.2542 - acc: 0.8964 - val_loss: 0.5977 - val_acc: 0.7608
Epoch 8/10
6375s - loss: 0.2191 - acc: 0.9121 - val_loss: 0.6583 - val_acc: 0.7534
Epoch 9/10
